{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n",
      "comp.graphics\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "sci.med\n",
      "sci.med\n",
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "#Training set \n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "#Print 10 target names\n",
    "for t in twenty_train.target[:10]:\n",
    "    print(twenty_train.target_names[t])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 0]\n",
      " [0 1 0 0 0 1 1]\n",
      " [1 1 1 0 1 1 0]]\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#-> Example of CountVectorizer 1\n",
    "tags = [\n",
    "  \"python, tools\",\n",
    "  \"linux, tools, ubuntu\",\n",
    "  \"distributed systems, linux, networking, tools\",\n",
    "]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "data = vec.fit_transform(tags).toarray()\n",
    "print(data)\n",
    "\n",
    "#-> Vocabulary in CountVectorize\n",
    "\n",
    "vocab = CountVectorizer(vocabulary=['hot', 'cold', 'old'])\n",
    "cv_words_in_vocab = vocab.fit_transform(['pease porridge hot', 'pease porridge cold', 'pease porridge in the pot', 'nine days old']).toarray()\n",
    "print(cv_words_in_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenizing text with count vecorize (document to feature vectors)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm 4690 \n",
      "is  18474\n"
     ]
    }
   ],
   "source": [
    "#->Frequency\n",
    "algo_freq = count_vect.vocabulary_.get(u'algorithm')\n",
    "is_freq = count_vect.vocabulary_.get(u'is')\n",
    "\n",
    "print(\"algorithm\",algo_freq,\n",
    "      \"\\nis \", is_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No if [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "After tf  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.01590913 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Prob: Longer documents have words occuring more freq\n",
    "#Soln: Divide by Total no of words in doc(TF)\n",
    "\n",
    "#Prob: Commoning occuring words have higher freq \n",
    "#Soln Mulitphy with incerve document frequency\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#fit the data \n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "#Transform count-matrix to tf-idf representation\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape\n",
    "\n",
    "#Before tf-idf\n",
    "print(\"No if\", X_train_counts.toarray()[:100])\n",
    "\n",
    "#After tf-idf \n",
    "print(\"After tf \",X_train_tf.toarray()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combining the last 2(fit+transform)into one \n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes - Multinomial\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  [3 1]\n",
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "#Predict outcome with docs_new \n",
    "\n",
    "#Transform docs_new\n",
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "#Predict uisng Multinomial NB\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "print(\"Predicted \", predicted)\n",
    "#print(twenty_train.target_names)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "#    print(\"doc \", doc, \"category \", category)\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a Pipeline\n",
    "\n",
    "# 1.Vectorize\n",
    "# 2.Transform\n",
    "# 3.Classify\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit MNB \n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Multinomial NB on Test data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Test set\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "    categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "\n",
    "#Predict on test data\n",
    "mnb_predicted = text_clf.predict(docs_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data \n",
      "Multinomial Naive Bayes  83.48868175765645\n"
     ]
    }
   ],
   "source": [
    "#Accuracy on test data\n",
    "\n",
    "multi_nb_accuracy = np.mean(mnb_predicted == twenty_test.target)\n",
    "print(\"Accuracy on test data \\n\"\n",
    "      \"Multinomial Naive Bayes \",\n",
    "      multi_nb_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier (loss=hinge)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42,\n",
    "                                           max_iter=5, tol=None)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting training data using svm\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "\n",
    "#Prediction on test data\n",
    "svm_predicted = text_clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data\n",
      "Multinomial Naive bayes  83.48868175765645\n",
      "SVM  91.27829560585884\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of SVM\n",
    "\n",
    "svm_accuracy = np.mean(svm_predicted == twenty_test.target)\n",
    "print(\"Accuracy on test data\")\n",
    "print(\"Multinomial Naive bayes \", multi_nb_accuracy*100)\n",
    "print(\"SVM \", svm_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.60      0.74       319\n",
      "         comp.graphics       0.96      0.89      0.92       389\n",
      "               sci.med       0.97      0.81      0.88       396\n",
      "soc.religion.christian       0.65      0.99      0.78       398\n",
      "\n",
      "           avg / total       0.88      0.83      0.84      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Performance - mnb\n",
    "\n",
    "#todo: pretty print\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, mnb_predicted,\n",
    "    target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.81      0.87       319\n",
      "         comp.graphics       0.88      0.97      0.92       389\n",
      "               sci.med       0.94      0.90      0.92       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "           avg / total       0.92      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performance - svm\n",
    "print(metrics.classification_report(twenty_test.target, svm_predicted,\n",
    "    target_names=twenty_test.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[192,   2,   6, 119],\n",
       "       [  2, 347,   4,  36],\n",
       "       [  2,  11, 322,  61],\n",
       "       [  2,   2,   1, 393]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix - mnb\n",
    "\n",
    "metrics.confusion_matrix(twenty_test.target, mnb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[258,  11,  15,  35],\n",
       "       [  4, 379,   3,   3],\n",
       "       [  5,  33, 355,   3],\n",
       "       [  5,  10,   4, 379]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion - svm\n",
    "\n",
    "metrics.confusion_matrix(twenty_test.target, svm_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search - Search best parameter of grid\n",
    "\n",
    "#TODO: \n",
    "# 1. word or bigrams??\n",
    "# 2. Put range of alpha\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (0.01, 0.001)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Classifier\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "\n",
    "#Fit the classifier on subset of categories\n",
    "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])\n",
    "gs_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9654408506867523\n",
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Complete training set\n",
    "\n",
    "gs_clf_full = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf_full = gs_clf_full.fit(twenty_train.data, twenty_train.target)\n",
    "gs_clf_full\n",
    "\n",
    "print(gs_clf_full.best_score_)            \n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf_full.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soc.religion.christian'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.graphics'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names[gs_clf.predict(['God is love', 'ksh or bash?'])[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "God is love  ->  soc.religion.christian\n",
      "ksh or bash?  ->  comp.graphics\n"
     ]
    }
   ],
   "source": [
    "#Predicting grid\n",
    "\n",
    "doc_predict = ['God is love', 'ksh or bash?']\n",
    "\n",
    "for index, doc in enumerate(doc_predict):\n",
    "    #print(\"index\", index)\n",
    "    pred_doc = twenty_test.target_names[gs_clf.predict(doc_predict)[index]] \n",
    "    #todo: figure syntax, why index not in (), does it predict all? Why doesn't it work without [index]\n",
    "    print(doc, \" -> \", pred_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Best parameters from grid search\n",
    "\n",
    "#todo: Mean cross-validated score of the best_estimator\n",
    "print(gs_clf.best_score_)            \n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 0 3 0 1 3 1 0 1 3 3 3 1 0 1 3 0 3 2 3 1 0 2 1 2 3 2 0 1 3 0 2 2 3 0\n",
      " 0 2 1 2 0 2 3 2 2 3 1 3 1 1 3 3 1 0 3 0 2 1 2 1 2 3 1 2 1 2 0 3 2 0 3 1 3\n",
      " 1 3 0 2 3 0 1 3 3 1 2 3 3 0 2 2 1 2 2 3 3 1 3 3 3 3]\n",
      "[2 2 2 0 3 0 1 3 1 2 1 3 0 3 1 2 1 3 0 3 2 3 1 0 2 1 1 3 2 0 1 3 0 2 2 0 0\n",
      " 0 2 1 2 0 2 3 2 2 3 1 3 1 1 2 3 2 0 3 0 1 1 2 1 2 3 1 2 1 2 0 2 2 0 3 1 3\n",
      " 1 0 0 2 3 0 1 0 3 1 2 3 3 0 2 2 1 2 2 1 3 1 0 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Grid search predict on test data\n",
    "gs_predict = gs_clf.predict(twenty_test.data)\n",
    "print(gs_predict[:100])\n",
    "\n",
    "\n",
    "gs_full_predict = gs_clf_full.predict(twenty_test.data)\n",
    "print(gs_full_predict[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 rows of data\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.93      0.71      0.80       319\n",
      "         comp.graphics       0.84      0.96      0.90       389\n",
      "               sci.med       0.91      0.83      0.87       396\n",
      "soc.religion.christian       0.80      0.91      0.85       398\n",
      "\n",
      "           avg / total       0.87      0.86      0.86      1502\n",
      "\n",
      "On complete categories\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.81      0.87       319\n",
      "         comp.graphics       0.88      0.97      0.92       389\n",
      "               sci.med       0.94      0.90      0.92       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "           avg / total       0.92      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Error: figure it\n",
    "#np.mean(gs_predict, twenty_test.data)\n",
    "\n",
    "# performance - Grid search\n",
    "print(\"400 rows of data\\n\", metrics.classification_report(twenty_test.target, gs_predict,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "print(\"On complete categories\\n\", metrics.classification_report(twenty_test.target, gs_full_predict,\n",
    "    target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[258,  11,  15,  35],\n",
       "       [  4, 379,   3,   3],\n",
       "       [  5,  33, 355,   3],\n",
       "       [  5,  10,   4, 379]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix - grid search  \n",
    "\n",
    "metrics.confusion_matrix(twenty_test.target, svm_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
